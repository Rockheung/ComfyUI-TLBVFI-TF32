# ComfyUI Frame Interpolation: ë©”ëª¨ë¦¬ ê´€ë¦¬ & ë³´ê°„ ì „ëµ ì¢…í•© ë¶„ì„

**ë¶„ì„ ëŒ€ìƒ**: [Fannovel16/ComfyUI-Frame-Interpolation](https://github.com/Fannovel16/ComfyUI-Frame-Interpolation)
**ë¶„ì„ ì¼ì**: 2025-10-15
**ë¶„ì„ì**: Claude Code (CC) + Codex
**ë¹„êµ ëŒ€ìƒ**: TLBVFI-TF32 êµ¬í˜„

---

## ëª©ì°¨

1. [Executive Summary](#executive-summary)
2. [Repository êµ¬ì¡°](#repository-êµ¬ì¡°)
3. [RIFE VFI ì‹¬ì¸µ ë¶„ì„](#rife-vfi-ì‹¬ì¸µ-ë¶„ì„)
4. [FILM VFI ì‹¬ì¸µ ë¶„ì„](#film-vfi-ì‹¬ì¸µ-ë¶„ì„)
5. [ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ ë¹„êµí‘œ](#ë©”ëª¨ë¦¬-ê´€ë¦¬-ì „ëµ-ë¹„êµí‘œ)
6. [ComfyUI í†µí•© íŒ¨í„´](#comfyui-í†µí•©-íŒ¨í„´)
7. [TLBVFI vs RIFE/FILM ë¹„êµ](#tlbvfi-vs-rifefilm-ë¹„êµ)
8. [Best Practices & ê¶Œì¥ì‚¬í•­](#best-practices--ê¶Œì¥ì‚¬í•­)
9. [ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì œì•ˆ](#ì‹¤í–‰-ê°€ëŠ¥í•œ-ê°œì„ -ì œì•ˆ)

---

## Executive Summary

### í•µì‹¬ ë°œê²¬ì‚¬í•­

| ì¸¡ë©´ | RIFE/FILM | TLBVFI (ìš°ë¦¬) | í‰ê°€ |
|------|-----------|---------------|------|
| **ëª¨ë¸ ìºì‹±** | âŒ ë§¤ ì‹¤í–‰ë§ˆë‹¤ ì¬ë¡œë“œ | âœ… ê¸€ë¡œë²Œ ìºì‹œ + ì••ë°• ê°ì§€ | **TLBVFI ìš°ìˆ˜** |
| **ë©”ëª¨ë¦¬ ì •ë¦¬** | âœ… ì£¼ê¸°ì  (`soft_empty_cache`) | âš ï¸ ìˆ˜ë™ (`cleanup_memory`) | **RIFE/FILM ìš°ìˆ˜** |
| **ComfyUI í†µí•©** | âœ… `model_management` í™œìš© | âŒ ë…ë¦½ì  êµ¬í˜„ | **RIFE/FILM ìš°ìˆ˜** |
| **ì¤‘ê°„ í”„ë ˆì„ ì²˜ë¦¬** | CPU ì¦‰ì‹œ ì´ë™ | GPU ëˆ„ì  í›„ ì¼ê´„ ì „ì†¡ | **RIFE/FILM ì•ˆì „** |
| **autograd ê´€ë¦¬** | FILM: âœ…, RIFE: âŒ | âœ… `torch.no_grad()` | **TLBVFI/FILM ìš°ìˆ˜** |
| **ë¹„ë™ê¸° ì „ì†¡** | âŒ ë™ê¸° ë¸”ë¡œí‚¹ | âœ… `non_blocking=True` | **TLBVFI ìš°ìˆ˜** |

### ì£¼ìš” êµí›ˆ

1. **`soft_empty_cache()` í•„ìˆ˜**: ComfyUI ìƒíƒœê³„ì™€ í˜‘ì¡°ì  ë©”ëª¨ë¦¬ ê´€ë¦¬
2. **ì£¼ê¸°ì  ì •ë¦¬ > ìˆ˜ë™ ì •ë¦¬**: ê¸´ ì›Œí¬í”Œë¡œìš°ì—ì„œ OOM ë°©ì§€
3. **CPU ì¶œë ¥ ëˆ„ì **: GPU VRAM ì••ë°• ìµœì†Œí™”ì˜ ê¸°ë³¸ íŒ¨í„´
4. **ëª¨ë¸ ìºì‹± íŠ¸ë ˆì´ë“œì˜¤í”„**: ë‹¨ìˆœí•¨ vs ì„±ëŠ¥ (TLBVFIëŠ” ì„±ëŠ¥ ì„ íƒì´ í•©ë¦¬ì )

---

## Repository êµ¬ì¡°

```
ComfyUI-Frame-Interpolation/
â”œâ”€â”€ vfi_utils.py              # ê³µí†µ ìœ í‹¸ë¦¬í‹° (í•µì‹¬!)
â”œâ”€â”€ vfi_models/
â”‚   â”œâ”€â”€ rife/
â”‚   â”‚   â”œâ”€â”€ __init__.py       # RIFE ë…¸ë“œ (89-107ì¤„)
â”‚   â”‚   â””â”€â”€ rife_arch.py      # IFNet êµ¬ì¡° + backwarp ìºì‹œ
â”‚   â”œâ”€â”€ film/
â”‚   â”‚   â”œâ”€â”€ __init__.py       # FILM ë…¸ë“œ (63-113ì¤„)
â”‚   â”‚   â””â”€â”€ film_arch.py      # TorchScript ëª¨ë¸
â”‚   â””â”€â”€ [10+ other VFI models]
â”œâ”€â”€ __init__.py               # NODE_CLASS_MAPPINGS
â””â”€â”€ config.yaml               # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •
```

**í•µì‹¬ ëª¨ë“ˆ**:
- `vfi_utils.py:124-207`: `_generic_frame_loop` - RIFEì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ í•µì‹¬
- `vfi_models/film/__init__.py:12-42`: FILMì˜ ì ì‘í˜• ìƒ˜í”Œë§ ì•Œê³ ë¦¬ì¦˜
- `comfy.model_management`: `get_torch_device()`, `soft_empty_cache()`

---

## RIFE VFI ì‹¬ì¸µ ë¶„ì„

### 1. ëª¨ë¸ ë¡œë”© & ìºì‹± ì „ëµ

```python
# vfi_models/rife/__init__.py:89-94
from .rife_arch import IFNet
model_path = load_file_from_github_release(MODEL_TYPE, ckpt_name)  # ë””ìŠ¤í¬ ìºì‹œ í™œìš©
arch_ver = CKPT_NAME_VER_DICT[ckpt_name]
interpolation_model = IFNet(arch_ver=arch_ver)
interpolation_model.load_state_dict(torch.load(model_path))
interpolation_model.eval().to(get_torch_device())  # ComfyUI ë””ë°”ì´ìŠ¤ ì¡´ì¤‘
```

**íŠ¹ì§•**:
- âŒ **ì¸-ë©”ëª¨ë¦¬ ìºì‹œ ì—†ìŒ**: ë§¤ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ë§ˆë‹¤ Python ì¬ì¸ìŠ¤í„´ìŠ¤í™”
- âœ… **ë””ìŠ¤í¬ ìºì‹œ**: `./ckpts/rife/` ì•„ë˜ì— ì²´í¬í¬ì¸íŠ¸ ë³´ê´€ (ì¬ë‹¤ìš´ë¡œë“œ ë°©ì§€)
- âœ… **ComfyUI í†µí•©**: `get_torch_device()`ë¡œ ê¸€ë¡œë²Œ ë””ë°”ì´ìŠ¤ ì„ íƒ ë”°ë¦„
- ğŸ“¦ **ë²„ì „ ê´€ë¦¬**: `CKPT_NAME_VER_DICT`ë¡œ ì•„í‚¤í…ì²˜ ë²„ì „ ë§¤í•‘ (4.0~4.9)

### 2. í”„ë ˆì„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
ì…ë ¥: IMAGE tensor (N, H, W, C)
  â†“
[preprocess_frames] â†’ (N, C, H, W) CPU tensor
  â†“
[generic_frame_loop] â† í•µì‹¬ ì²˜ë¦¬ ë£¨í”„
  â”œâ”€ ì‚¬ì „ í• ë‹¹: torch.zeros(multiplier*N, C, H, W, device="cpu")
  â”œâ”€ For each pair (i, i+1):
  â”‚   â”œâ”€ frame0, frame1 â†’ GPU (float32)
  â”‚   â”œâ”€ For timestep in [1/m, 2/m, ..., (m-1)/m]:
  â”‚   â”‚   â””â”€ IFNet(frame0, frame1, timestep) â†’ mid_frame
  â”‚   â”‚   â””â”€ mid_frame.detach().cpu() â†’ ì¦‰ì‹œ CPU ì´ë™
  â”‚   â”œâ”€ ì¹´ìš´í„° ì¦ê°€
  â”‚   â””â”€ If counter >= clear_cache_after_n_frames:
  â”‚       â”œâ”€ soft_empty_cache()  # ComfyUI ë©”ëª¨ë¦¬ í˜‘ìƒ
  â”‚       â”œâ”€ gc.collect()
  â”‚       â””â”€ counter = 0
  â””â”€ soft_empty_cache()  # ìµœì¢… ì •ë¦¬
  â†“
[postprocess_frames] â†’ (N, H, W, C) ì¶œë ¥
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜

#### A. CPU ì‚¬ì „ í• ë‹¹ ì „ëµ
```python
# vfi_utils.py:147
output_frames = torch.zeros(
    multiplier * frames.shape[0],
    *frames.shape[1:],
    dtype=dtype,  # float16 (ë©”ëª¨ë¦¬ ì ˆì•½)
    device="cpu"  # GPU VRAM ì••ë°• ë°©ì§€
)
```

**ì¥ì **:
- ì¶œë ¥ í¬ê¸°ë¥¼ ë¯¸ë¦¬ ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íš¨ìœ¨ì 
- GPU VRAM ì‚¬ìš© ìµœì†Œí™” (í˜„ì¬ í˜ì–´ + ëª¨ë¸ë§Œ)

**íŠ¸ë ˆì´ë“œì˜¤í”„**:
- í° ë¹„ë””ì˜¤ëŠ” RAM ì‚¬ì „ í• ë‹¹ì´ í´ ìˆ˜ ìˆìŒ
- FILMì€ ë™ì  ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© (ìœ ì—°í•˜ì§€ë§Œ concat ì˜¤ë²„í—¤ë“œ)

#### B. ì¦‰ì‹œ CPU ì „ì†¡
```python
# vfi_utils.py:170-176
middle_frame = return_middle_frame_function(
    frame0.to(DEVICE),
    frame1.to(DEVICE),
    timestep,
    *args
).detach().cpu()  # â† í•µì‹¬: ì¦‰ì‹œ CPUë¡œ, gradient ëŠê¸°
```

**ì¤‘ìš”**: RIFEëŠ” `torch.no_grad()`ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- `.detach()` ì „ì— autograd ë©”íƒ€ë°ì´í„°ê°€ ì ê¹ ìƒì„±ë¨
- FILM/TLBVFIë³´ë‹¤ ì•½ê°„ ë” ë†’ì€ VRAM ì˜¤ë²„í—¤ë“œ

#### C. ì£¼ê¸°ì  ìºì‹œ í´ë¦¬ì–´ (ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥)
```python
# vfi_utils.py:186-192
if number_of_frames_processed >= clear_cache_after_n_frames:
    print("Comfy-VFI: Clearing cache...", end=' ')
    soft_empty_cache()  # ComfyUIì˜ ìŠ¤ë§ˆíŠ¸ ìºì‹œ ê´€ë¦¬
    number_of_frames_processed = 0
    print("Done cache clearing")
gc.collect()  # ë§¤ ë°˜ë³µë§ˆë‹¤ Python GC
```

**`soft_empty_cache()` vs `torch.cuda.empty_cache()`**:
- `soft_empty_cache()`: ComfyUIì˜ ë‹¤ë¥¸ ë…¸ë“œì™€ ë©”ëª¨ë¦¬ í˜‘ìƒ
- ë‹¨ìˆœ `empty_cache()`: ëª¨ë“  CUDA ìºì‹œ ê°•ì œ í•´ì œ (ë‹¤ë¥¸ ì›Œí¬í”Œë¡œìš° ì˜í–¥)

#### D. backwarp ê·¸ë¦¬ë“œ ìºì‹±
```python
# vfi_models/rife/rife_arch.py:16-70
backwarp_tenGrid = {}  # ê¸€ë¡œë²Œ ë”•ì…”ë„ˆë¦¬

def warp(tenIn, tenFlow):
    if str(tenFlow.device) + str(tenFlow.shape) not in backwarp_tenGrid:
        # ìƒ˜í”Œë§ ê·¸ë¦¬ë“œ ê³„ì‚° & ìºì‹±
        backwarp_tenGrid[str(tenFlow.device) + str(tenFlow.shape)] = ...
    return torch.nn.functional.grid_sample(...)
```

**íš¨ê³¼**: ë™ì¼ í•´ìƒë„ ì²˜ë¦¬ ì‹œ ê·¸ë¦¬ë“œ ì¬ê³„ì‚° ë°©ì§€ (ì†Œí­ ì„±ëŠ¥ í–¥ìƒ)

---

## FILM VFI ì‹¬ì¸µ ë¶„ì„

### 1. ëª¨ë¸ ë¡œë”© ì „ëµ

```python
# vfi_models/film/__init__.py:73-76
model_path = load_file_from_github_release(MODEL_TYPE, ckpt_name)
model = torch.jit.load(model_path, map_location='cpu')  # TorchScript
model.eval()
model = model.to(DEVICE)  # CPU ë¨¼ì € ë¡œë“œ í›„ GPU ì´ë™ (ì•ˆì „)
```

**ì°¨ë³„ì **:
- **TorchScript íŒ¨í‚¤ì§•**: ë‹¨ì¼ `.pt` íŒŒì¼ë¡œ ë°°í¬ (ì•„í‚¤í…ì²˜ ì½”ë“œ ë¶ˆí•„ìš”)
- **CPU ë¨¼ì € ë¡œë“œ**: GPU ìŠ¤íŒŒì´í¬ ë°©ì§€ (í° ëª¨ë¸ì— ìœ ë¦¬)
- âŒ **ìºì‹± ì—†ìŒ**: RIFEì™€ ë™ì¼í•˜ê²Œ ë§¤ë²ˆ ì¬ë¡œë“œ

### 2. ì ì‘í˜• ì¬ê·€ì  ë³´ê°„ ì•Œê³ ë¦¬ì¦˜

FILMì˜ í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ:

```python
# vfi_models/film/__init__.py:12-42
def inference(model, img_batch_1, img_batch_2, inter_frames):
    results = [img_batch_1, img_batch_2]
    idxes = [0, inter_frames + 1]
    remains = list(range(1, inter_frames + 1))
    splits = torch.linspace(0, 1, inter_frames + 2)  # ì‹œê°„ ë¶„í• 

    for _ in range(len(remains)):
        # 1. ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°: ì–´ë–¤ í”„ë ˆì„ì„ ë‹¤ìŒì— ìƒì„±í• ì§€ ê²°ì •
        starts = splits[idxes[:-1]]
        ends = splits[idxes[1:]]
        distances = ((splits[None, remains] - starts[:, None]) /
                     (ends[:, None] - starts[:, None]) - .5).abs()

        # 2. ê°€ì¥ ì¤‘ì•™ì— ê°€ê¹Œìš´ ìœ„ì¹˜ ì„ íƒ
        matrix = torch.argmin(distances).item()
        start_i, step = np.unravel_index(matrix, distances.shape)
        end_i = start_i + 1

        # 3. ë™ì  timestep ê³„ì‚°
        x0 = results[start_i].to(DEVICE)
        x1 = results[end_i].to(DEVICE)
        dt = (splits[remains[step]] - splits[idxes[start_i]]) /
             (splits[idxes[end_i]] - splits[idxes[start_i]])

        # 4. ì¶”ë¡  & ì‚½ì…
        with torch.no_grad():  # â† RIFEì™€ ë‹¬ë¦¬ ëª…ì‹œì  no_grad
            prediction = model(x0, x1, dt)

        insert_position = bisect.bisect_left(idxes, remains[step])
        idxes.insert(insert_position, remains[step])
        results.insert(insert_position, prediction.clamp(0, 1).float())
        del remains[step]

    return [tensor.flip(0) for tensor in results]
```

**ì•Œê³ ë¦¬ì¦˜ íŠ¹ì§•**:
- ğŸ¯ **ì ì‘í˜• ìƒ˜í”Œë§**: ì‹œê°„ì ìœ¼ë¡œ ê· ë“± ë¶„ë°° (ì¤‘ì•™ë¶€í„° ìƒì„±)
- ğŸ”„ **ì¬ê·€ì **: ì´ë¯¸ ìƒì„±ëœ í”„ë ˆì„ ì‚¬ì´ì— ìƒˆ í”„ë ˆì„ ì‚½ì…
- ğŸ“Š **ë™ì  timestep**: í”„ë ˆì„ ê°„ ê±°ë¦¬ ê¸°ë°˜ ê³„ì‚°
- ğŸ’¾ **ë©”ëª¨ë¦¬ íš¨ìœ¨**: í•œ ë²ˆì— 2ê°œ í”„ë ˆì„ë§Œ GPU

**RIFEì™€ì˜ ì°¨ì´**:
- RIFE: ìˆœì°¨ì  íƒ€ì„ìŠ¤í… (1/m, 2/m, ..., (m-1)/m)
- FILM: ê±°ë¦¬ ìµœì†Œí™” ê¸°ë°˜ ì ì‘í˜• ì„ íƒ

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬ (RIFEì™€ ì°¨ì´ì )

```python
# vfi_models/film/__init__.py:79-113
output_frames = []  # ë™ì  ë¦¬ìŠ¤íŠ¸ (ì‚¬ì „ í• ë‹¹ X)

for frame_itr in range(len(frames) - 1):
    frame_0 = frames[frame_itr:frame_itr+1].to(DEVICE).float()
    frame_1 = frames[frame_itr+1:frame_itr+2].to(DEVICE).float()

    result = inference(model, frame_0, frame_1, multipliers[frame_itr] - 1)

    # CPU ì´ë™ & ë¦¬ìŠ¤íŠ¸ ëˆ„ì 
    output_frames.extend([
        frame.detach().cpu().to(dtype=dtype)
        for frame in result[:-1]  # ë§ˆì§€ë§‰ í”„ë ˆì„ ì œì™¸ (ì¤‘ë³µ ë°©ì§€)
    ])

    # ë™ì¼í•œ ì£¼ê¸°ì  ìºì‹œ í´ë¦¬ì–´
    if processed_count >= clear_cache_after_n_frames:
        soft_empty_cache()
        gc.collect()

output_frames.append(frames[-1:])
out = torch.cat(output_frames, dim=0)  # ìµœì¢… concat
soft_empty_cache()  # ìµœì¢… ì •ë¦¬
```

**RIFEì™€ ë¹„êµ**:
| ì¸¡ë©´ | RIFE | FILM |
|------|------|------|
| **ì¶œë ¥ í• ë‹¹** | ì‚¬ì „ í• ë‹¹ `torch.zeros` | ë™ì  `list.extend` |
| **ë©”ëª¨ë¦¬ ì˜ˆì¸¡** | ì‰¬ì›€ (í¬ê¸° ê³ ì •) | ì–´ë ¤ì›€ (ê°€ë³€) |
| **ìœ ì—°ì„±** | ë‚®ìŒ | ë†’ìŒ (per-pair multiplier) |
| **concat ì˜¤ë²„í—¤ë“œ** | ì—†ìŒ | ìˆìŒ (ìµœì¢… `torch.cat`) |

---

## ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ ë¹„êµí‘œ

### ê³µí†µ íŒ¨í„´

| ì „ëµ | RIFE | FILM | TLBVFI | í‰ê°€ |
|------|------|------|--------|------|
| **CPU ì¶œë ¥ ëˆ„ì ** | âœ… ì‚¬ì „ í• ë‹¹ | âœ… ë™ì  ë¦¬ìŠ¤íŠ¸ | âœ… ìµœì¢…ë§Œ | **ê³µí†µ Best Practice** |
| **detach() ì‚¬ìš©** | âœ… | âœ… | âœ… | **í•„ìˆ˜ íŒ¨í„´** |
| **ì£¼ê¸°ì  ì •ë¦¬** | âœ… 10í”„ë ˆì„ | âœ… 10í”„ë ˆì„ | âŒ ì—†ìŒ | **RIFE/FILM ìš°ìˆ˜** |
| **gc.collect()** | âœ… ë§¤ ë°˜ë³µ | âœ… ë§¤ ë°˜ë³µ | âœ… ìˆ˜ë™ | **ê³µí†µ** |
| **ìµœì¢… ì •ë¦¬** | âœ… soft_empty | âœ… soft_empty | âœ… cleanup_memory | **RIFE/FILM ìš°ìˆ˜** |

### ì°¨ë³„í™” ìš”ì†Œ

| ì¸¡ë©´ | RIFE | FILM | TLBVFI |
|------|------|------|--------|
| **ëª¨ë¸ ìºì‹±** | âŒ ë§¤ë²ˆ ë¡œë“œ | âŒ ë§¤ë²ˆ ë¡œë“œ | âœ… ê¸€ë¡œë²Œ ìºì‹œ |
| **autograd** | âŒ detachë§Œ | âœ… no_grad | âœ… no_grad |
| **ë¹„ë™ê¸° ì „ì†¡** | âŒ ë™ê¸° | âŒ ë™ê¸° | âœ… non_blocking |
| **ì¶œë ¥ dtype** | float16 | float32 | float32 |
| **ëª¨ë¸ íƒ€ì…** | í‘œì¤€ PyTorch | TorchScript | í‘œì¤€ PyTorch |
| **ë©”ëª¨ë¦¬ ì••ë°• ê°ì§€** | âŒ | âŒ | âœ… ìë™ ì²´í¬ |

---

## ComfyUI í†µí•© íŒ¨í„´

### RIFE/FILMì˜ í†µí•© ë°©ì‹

```python
from comfy.model_management import get_torch_device, soft_empty_cache

DEVICE = get_torch_device()  # ê¸€ë¡œë²Œ ë””ë°”ì´ìŠ¤ ì„ íƒ ì¡´ì¤‘

# ë…¸ë“œ ë“±ë¡
NODE_CLASS_MAPPINGS = {
    "RIFE VFI": RIFE_VFI,
    "FILM VFI": FILM_VFI,
}
```

**íŠ¹ì§•**:
- âœ… **ìµœì†Œ ì¹¨ì…ì **: ë””ë°”ì´ìŠ¤ ì„ íƒ & ìºì‹œ ê´€ë¦¬ë§Œ í™œìš©
- âœ… **í‘œì¤€ íŒ¨í„´**: ComfyUIì˜ ë‹¤ë¥¸ VFI ë…¸ë“œì™€ ì¼ê´€ì„±
- âŒ **ê³ ê¸‰ ê¸°ëŠ¥ ë¯¸ì‚¬ìš©**: `LoadedModel`, `model_management` ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±

### Frame Skipping (InterpolationStateList)

```python
# vfi_utils.py:27-59
class InterpolationStateList:
    def __init__(self, frame_indices: List[int], is_skip_list: bool):
        self.frame_indices = frame_indices
        self.is_skip_list = is_skip_list

    def is_frame_skipped(self, frame_index):
        is_frame_in_list = frame_index in self.frame_indices
        return (self.is_skip_list and is_frame_in_list) or
               (not self.is_skip_list and not is_frame_in_list)
```

**ì‚¬ìš© ì˜ˆ**:
```python
# ì›Œí¬í”Œë¡œìš°ì—ì„œ
states = InterpolationStateList([10, 20, 30], is_skip_list=True)
# â†’ 10, 20, 30ë²ˆ í”„ë ˆì„ì€ ë³´ê°„ ìŠ¤í‚µ
```

**ì¥ì **: ì›Œí¬í”Œë¡œìš° ì£¼ë„ì  ì œì–´ (ë…¸ë“œ ìƒíƒœ ì—†ìŒ)

---

## TLBVFI vs RIFE/FILM ë¹„êµ

### ì½”ë“œ ë¹„êµ

#### TLBVFI (í˜„ì¬ êµ¬í˜„)
```python
# nodes/tlbvfi_interpolator.py
_MODEL_CACHE = {}  # ê¸€ë¡œë²Œ ìºì‹±

def interpolate(self, frame_pair, model_name, times_to_interpolate, gpu_id, ...):
    device = torch.device(f"cuda:{gpu_id}")

    # ëª¨ë¸ ë¡œë”© with ìºì‹± & ì••ë°• ê°ì§€
    cache_key = f"{model_name}_{gpu_id}"
    if cache_key in _MODEL_CACHE:
        model = _MODEL_CACHE[cache_key]
    else:
        # ë©”ëª¨ë¦¬ ì••ë°• ìë™ ê°ì§€
        if device.type == 'cuda':
            mem_stats = get_memory_stats(device)
            if mem_stats['free'] < 4.0:
                clear_model_cache()  # ìë™ ì •ë¦¬

        model = load_tlbvfi_model(model_name, device)
        _MODEL_CACHE[cache_key] = model

    # GPUì—ì„œ ëª¨ë“  ë°˜ë³µ ë³´ê°„ ì²˜ë¦¬
    current_frames = [frame1, frame2]
    for iteration in range(times_to_interpolate):
        temp_frames = [current_frames[0]]
        for j in range(len(current_frames) - 1):
            with torch.no_grad():
                mid_frame = model.sample(current_frames[j], current_frames[j+1])
            temp_frames.extend([mid_frame, current_frames[j+1]])
        current_frames = temp_frames

    # í›„ì²˜ë¦¬: GPU â†’ CPU (ìµœì¢…ë§Œ)
    processed_frames = []
    for frame in frames_to_process:
        frame_cpu = frame.squeeze(0).to('cpu', non_blocking=True)  # ë¹„ë™ê¸°
        frame_cpu = (frame_cpu + 1.0) / 2.0
        frame_cpu = frame_cpu.clamp(0, 1)
        processed_frames.append(frame_cpu.permute(1, 2, 0))

    result = torch.stack(processed_frames, dim=0)

    # ì •ë¦¬
    del current_frames, temp_frames, frame1, frame2
    cleanup_memory(device, force_gc=True)  # ìˆ˜ë™ ì •ë¦¬

    return (result,)
```

#### RIFE/FILM íŒ¨í„´
```python
# ë§¤ë²ˆ ë¡œë“œ
model = load_model(model_path)
model.eval().to(device)

# í”„ë ˆì„ë§ˆë‹¤ GPU â†’ CPU ì¦‰ì‹œ ì „ì†¡
for pair in pairs:
    result = model(pair).detach().cpu()  # ì¦‰ì‹œ
    output.append(result)

    if count >= 10:
        soft_empty_cache()  # ì£¼ê¸°ì 
        count = 0
```

### ì¥ë‹¨ì  ë¹„êµí‘œ

| ì¸¡ë©´ | TLBVFI | RIFE/FILM | ìŠ¹ì |
|------|--------|-----------|------|
| **ì¬ì‹¤í–‰ ì†ë„** | âš¡ ì¦‰ì‹œ (ìºì‹±) | ğŸŒ 3-5ì´ˆ ë¡œë“œ | **TLBVFI** |
| **ë©”ëª¨ë¦¬ ì•ˆì „ì„±** | âœ… ìë™ ê°ì§€ | âœ… ì£¼ê¸°ì  ì •ë¦¬ | **ë™ì ** |
| **ComfyUI í˜‘ì¡°** | âŒ ë…ë¦½ì  | âœ… soft_empty_cache | **RIFE/FILM** |
| **GPU ì¤‘ê°„ ëˆ„ì ** | âš ï¸ ë°˜ë³µ ì‹œ ì••ë°• | âœ… ì¦‰ì‹œ CPU | **RIFE/FILM** |
| **ë¹„ë™ê¸° ìµœì í™”** | âœ… non_blocking | âŒ ë™ê¸° | **TLBVFI** |
| **ë‹¨ìˆœì„±** | âŒ ë³µì¡ (ìºì‹± ë¡œì§) | âœ… ë‹¨ìˆœ | **RIFE/FILM** |
| **autograd ê´€ë¦¬** | âœ… no_grad | RIFE: âŒ, FILM: âœ… | **TLBVFI/FILM** |

### Codexì˜ ì¶”ê°€ ë°œê²¬

- **ì ì‘í˜• ì •ë¦¬ ì£¼ê¸°**: `calculate_cleanup_interval`ì´ ì‹¤ì‹œê°„ VRAM í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬ ì£¼ê¸°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. RIFE/FILMì´ ê³ ì • 10í”„ë ˆì„ ì£¼ê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ëŒ€ë¹„ë˜ëŠ” ì°¨ë³„ì ì…ë‹ˆë‹¤.
- **ë°°ì¹˜ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸**: TLBVFIëŠ” non-blocking CPU ì „ì†¡ìœ¼ë¡œ í”„ë ˆì„ ë°°ì¹˜ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬í•˜ë©°, ì‚¬ìš© ê°€ëŠ¥í•œ RAMì„ ê¸°ì¤€ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤. (`tlbvfi_node.py:182-215`)
- **ëª…ì‹œì  ëª¨ë¸ ì–¸ë¡œë“œ**: ì‹¤í–‰ ì¢…ë£Œ ì‹œ ëª¨ë¸ì„ CPUë¡œ ë˜ëŒë¦¬ê³  `torch.cuda.empty_cache()`ë¥¼ í˜¸ì¶œí•´ VRAMì„ ì¦‰ì‹œ íšŒìˆ˜í•©ë‹ˆë‹¤. (`tlbvfi_node.py:431-482`)
- **ìˆ˜ë™ ìºì‹œ ê°„ê²© ë…¸ì¶œ í•„ìš”**: Codex ë¶„ì„ì— ë”°ë¥´ë©´ ê³ ê¸‰ ì‚¬ìš©ìê°€ VRAM ì—¬ê±´ì— ë§ì¶° ì •ë¦¬ ê°„ê²©ì„ ì§ì ‘ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì„ ì œê³µí•˜ë©´ ìš´ì˜ ì•ˆì •ì„±ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.

---

## Best Practices & ê¶Œì¥ì‚¬í•­

### 1. ComfyUI í†µí•© ê°œì„  (ë†’ìŒ ìš°ì„ ìˆœìœ„)

**í˜„ì¬ TLBVFI**:
```python
cleanup_memory(device, force_gc=True)
```

**ê¶Œì¥**:
```python
from comfy.model_management import soft_empty_cache

# ì£¼ê¸°ì  ì •ë¦¬ (ChunkProcessorì— ì¶”ê°€)
if (pair_idx + 1) % 10 == 0:
    soft_empty_cache()  # ComfyUIì™€ í˜‘ì¡°
    gc.collect()

# ìµœì¢… ì •ë¦¬
soft_empty_cache()
```

**ì´ìœ **:
- ComfyUIì˜ ë‹¤ë¥¸ ë…¸ë“œì™€ ë©”ëª¨ë¦¬ í˜‘ìƒ
- ë©€í‹° ì›Œí¬í”Œë¡œìš° í™˜ê²½ì—ì„œ ì•ˆì „
- í‘œì¤€ íŒ¨í„´ ì¤€ìˆ˜

### 2. torch.no_grad() ë³´ì¥ (ë†’ìŒ)

**í˜„ì¬**: ì´ë¯¸ êµ¬í˜„ë¨ âœ…
```python
with torch.no_grad():
    mid_frame = model.sample(...)
```

**í™•ì¸ í•„ìš”**: ëª¨ë“  ì¶”ë¡  ê²½ë¡œì— ì ìš©ë˜ì—ˆëŠ”ì§€ ê²€ì¦

### 3. ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥í•œ ìºì‹œ í´ë¦¬ì–´ (ì¤‘ê°„)

```python
class TLBVFI_ChunkProcessor:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                ...
                "clear_cache_after_n_pairs": ("INT", {
                    "default": 10,
                    "min": 1,
                    "max": 100,
                    "tooltip": "ì£¼ê¸°ì  ìºì‹œ í´ë¦¬ì–´ ë¹ˆë„ (ë‚®ì„ìˆ˜ë¡ ì•ˆì „, ëŠë¦¼)"
                }),
            }
        }

    def process_all_chunks(self, ..., clear_cache_after_n_pairs=10):
        for pair_idx in range(total_pairs):
            ...
            if (pair_idx + 1) % clear_cache_after_n_pairs == 0:
                soft_empty_cache()
```

**íš¨ê³¼**: ì‚¬ìš©ìê°€ ë©”ëª¨ë¦¬/ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ ì œì–´

### 4. ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì¶”ê°€ (ë‚®ìŒ)

```python
def process_all_chunks(self, ...):
    for pair_idx in range(total_pairs):
        if pair_idx % 50 == 0:  # 50ê°œë§ˆë‹¤ ë¡œê¹…
            mem_stats = get_memory_stats(device)
            print(f"[Pair {pair_idx}/{total_pairs}] "
                  f"VRAM: {mem_stats['used']:.1f}/{mem_stats['total']:.1f} GB")
```

### 5. TorchScript íŒ¨í‚¤ì§• ê³ ë ¤ (ì„ íƒ)

**Codex ì œì•ˆ** (line 134-141):
> FILMì˜ TorchScript íŒ¨í‚¤ì§•ì€ ë¡œë”©ì„ ë‹¨ìˆœí™”í•˜ê³  CPU ì¹œí™”ì .
> TLBVFIì˜ ì¶”ë¡  ê²½ë¡œë¥¼ TorchScriptë¡œ exportí•˜ë©´ í–¥í›„ ë¡œë“œ ì†ë„ ê°œì„  ê°€ëŠ¥.

**êµ¬í˜„ ë‚œì´ë„**: ë†’ìŒ (TLBVFI ëª¨ë¸ êµ¬ì¡° ë³µì¡ë„ ê³ ë ¤)

### 6. dtype ìµœì í™” (ì„ íƒ)

í˜„ì¬ TLBVFIëŠ” `float32`, RIFEëŠ” `float16` ì‚¬ìš©.

**ì˜µì…˜ A: ì¶œë ¥ë§Œ float16**
```python
processed_frames = []
for frame in frames_to_process:
    frame_cpu = frame.squeeze(0).to('cpu', non_blocking=True)
    frame_cpu = (frame_cpu + 1.0) / 2.0
    frame_cpu = frame_cpu.clamp(0, 1).to(dtype=torch.float16)  # ì €ì¥ ì‹œ ë³€í™˜
    processed_frames.append(frame_cpu.permute(1, 2, 0))
```

**íš¨ê³¼**: ë©”ëª¨ë¦¬ ì ˆì•½ (ì‹¤ì§ˆì  ì •í™•ë„ ì†ì‹¤ ê±°ì˜ ì—†ìŒ)

---

## ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì œì•ˆ

### Phase 1: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥ (1-2ì‹œê°„)

1. **ComfyUI í†µí•©**
   ```python
   # utils/memory_manager.pyì— ì¶”ê°€
   def soft_empty_cache_wrapper():
       """ComfyUIì˜ soft_empty_cacheë¥¼ ì‚¬ìš©í•˜ë˜, ì—†ìœ¼ë©´ fallback"""
       try:
           from comfy.model_management import soft_empty_cache
           soft_empty_cache()
       except ImportError:
           torch.cuda.empty_cache()
       gc.collect()
   ```

2. **ChunkProcessorì— ì£¼ê¸°ì  ì •ë¦¬**
   ```python
   # nodes/chunk_processor.py:240-280
   for pair_idx in tqdm(range(total_pairs)):
       ...
       if (pair_idx + 1) % 10 == 0:
           from utils.memory_manager import soft_empty_cache_wrapper
           soft_empty_cache_wrapper()
   ```

### Phase 2: ì‚¬ìš©ì„± ê°œì„  (2-4ì‹œê°„)

3. **ì‚¬ìš©ì ì„¤ì • ì¶”ê°€**
   - `clear_cache_after_n_pairs` íŒŒë¼ë¯¸í„°
   - ê¸°ë³¸ê°’ 10, íˆ´íŒìœ¼ë¡œ ì„¤ëª…

4. **ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ë¡œê¹…**
   - 50 í˜ì–´ë§ˆë‹¤ VRAM ì‚¬ìš©ëŸ‰ ì¶œë ¥
   - ë””ë²„ê¹… ì‹œ ìœ ìš©

### Phase 3: ìµœì í™” (ì„ íƒì )

5. **dtype ìµœì í™”**
   - ì¶œë ¥ float16 ë³€í™˜ í…ŒìŠ¤íŠ¸
   - í’ˆì§ˆ ë¹„êµ í›„ ê²°ì •

6. **TorchScript ì¡°ì‚¬**
   - TLBVFI ëª¨ë¸ì˜ script ê°€ëŠ¥ì„± ê²€í† 
   - ROI í‰ê°€ í›„ ì§„í–‰ ì—¬ë¶€ ê²°ì •

---

## ê²°ë¡ 

### í•µì‹¬ Takeaways

1. **RIFE/FILMì€ ë‹¨ìˆœí•¨ì„ í†µí•œ ì•ˆì •ì„±**
   - ëª¨ë¸ ì¬ë¡œë“œ ì˜¤ë²„í—¤ë“œë¥¼ ê°ìˆ˜
   - ì£¼ê¸°ì  ì •ë¦¬ë¡œ OOM ë°©ì§€
   - ComfyUI í‘œì¤€ íŒ¨í„´ ì¤€ìˆ˜

2. **TLBVFIëŠ” ì„±ëŠ¥ì„ ìœ„í•œ ë³µì¡ì„±**
   - ëª¨ë¸ ìºì‹±ìœ¼ë¡œ ì¬ì‹¤í–‰ ì†ë„ í–¥ìƒ
   - ë©”ëª¨ë¦¬ ì••ë°• ìë™ ê°ì§€
   - ë¹„ë™ê¸° ì „ì†¡ ìµœì í™”

3. **ë‘ ì ‘ê·¼ì˜ í•˜ì´ë¸Œë¦¬ë“œê°€ ì´ìƒì **
   - TLBVFIì˜ ìºì‹± + RIFE/FILMì˜ ì£¼ê¸°ì  ì •ë¦¬
   - ì„±ëŠ¥ê³¼ ì•ˆì •ì„± ëª¨ë‘ í™•ë³´

### ë‹¤ìŒ ë‹¨ê³„

1. âœ… **ì¦‰ì‹œ ì ìš©**: `soft_empty_cache()` í†µí•©
2. â° **ë‹¨ê¸°**: ì£¼ê¸°ì  ìºì‹œ í´ë¦¬ì–´ ì¶”ê°€
3. ğŸ“Š **ì¤‘ê¸°**: ì‚¬ìš©ì ì„¤ì • & í”„ë¡œíŒŒì¼ë§
4. ğŸ”¬ **ì¥ê¸°**: TorchScript íŒ¨í‚¤ì§• ì¡°ì‚¬

---

## ì°¸ê³ ìë£Œ

- **ì†ŒìŠ¤ ì½”ë“œ**: [Fannovel16/ComfyUI-Frame-Interpolation](https://github.com/Fannovel16/ComfyUI-Frame-Interpolation)
- **Codex ë¶„ì„ ìš”ì•½**: ë³¸ë¬¸ ã€ŒCodexì˜ ì¶”ê°€ ë°œê²¬ã€ ì ˆì— í†µí•© ë°˜ì˜
- **ComfyUI ë¬¸ì„œ**: [docs.comfy.org](https://docs.comfy.org)
- **RIFE Paper**: [Real-Time Intermediate Flow Estimation (ECCV 2022)](https://arxiv.org/abs/2011.06294)
- **FILM Paper**: [Frame Interpolation for Large Motion (ECCV 2022)](https://arxiv.org/abs/2202.04901)
- **ComfyUI Model Management**: [`comfy/model_management.py`](https://github.com/comfyanonymous/ComfyUI/blob/master/comfy/model_management.py)

### ì£¼ìš” íŒŒì¼ ì°¸ì¡°

| íŒŒì¼ | ë¼ì¸ | ë‚´ìš© |
|------|------|------|
| `vfi_utils.py` | 124-207 | `_generic_frame_loop` í•µì‹¬ ë¡œì§ |
| `vfi_models/rife/__init__.py` | 89-107 | RIFE ë…¸ë“œ êµ¬í˜„ |
| `vfi_models/film/__init__.py` | 12-42, 63-113 | FILM ì•Œê³ ë¦¬ì¦˜ & ë…¸ë“œ |
| `vfi_models/rife/rife_arch.py` | 16-70 | backwarp ê·¸ë¦¬ë“œ ìºì‹± |
| `tlbvfi_node.py` | 86-177, 304-479 | TLBVFI ì ì‘í˜• ì •ë¦¬ & ì–¸ë¡œë“œ |

---

**ë¬¸ì„œ ë²„ì „**: 2.0 (CC + Codex í†µí•©)
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-15
**ìƒíƒœ**: âœ… ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ
